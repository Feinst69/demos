---
title: "R Notebook"
output: html_notebook
---


## Importation des données


Importation des librairies
```{r}
library(readxl)
library(tidyverse)
library(ggcorrplot)
library(ggplot2)
library(reshape2)
library(dplyr)
library(compositions)
library(FactoMineR)
library(factoextra)
```


chargement des fichiers
```{r}
df <- read_excel("data_abs.xlsx")
```

Afficher les premières lignes
```{r}
head(df)
```


Données statistiques
```{r}
summary(df)
```

## Analyse univarié


```{r}
# Distribution du taux d'abstention (TxAbs)
ggplot(df, aes(x = txabs)) + 
  geom_histogram(binwidth = 1, fill = "red", color = "black", alpha = 0.7) + 
  labs(title = "Distribution du taux d'abstention", x = "Taux d'abstention", y = "Nombre de départements") +
  theme_minimal()
```

Le graphique montre la répartition du taux d'abstention dans les différents départements.
On peut observer que la plupart des départements ont un taux d'abstention compris entre 15% et 25%.


```{r}
# Distribution du taux de pauvreté (TxPauv)
ggplot(df, aes(x = TxPauv)) + 
  geom_histogram(binwidth = 1, fill = "gray", color = "black", alpha = 0.7) + 
  labs(title = "Distribution du taux de pauvreté", x = "Taux de pauvreté", y = "Nombre de départements") +
  theme_minimal()
```

La plupart des départements ont un taux de pauvreté entre 10% et 20%. 



```{r}
# Distribution du taux de chômage (txcho)
ggplot(df, aes(x = txcho)) + 
  geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) + 
  labs(title = "Distribution du taux de chômage", x = "Taux de chômage", y = "Nombre de départements") +
  theme_minimal()
```

Le taux de chômage varie significativement entre les départements, avec des valeurs principalement comprises entre 6% et 15%.


## Analyse bivariée


```{r}
# Relation entre le taux d'abstention et le taux de pauvreté
ggplot(df, aes(x = TxPauv, y = txabs)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Taux de pauvreté en fonction du Taux d'abstention", x = "Taux de pauvreté", y = "Taux d'abstention") +
  theme_minimal()
```


Il y a une corrélation positive entre le taux de pauvreté et le taux d'abstention.


```{r}
# Relation entre le taux d'abstention et le taux de chômage
ggplot(df, aes(x = txcho, y = txabs)) +
  geom_point(color = "green") +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Taux de chômage vs Taux d'abstention", x = "Taux de chômage", y = "Taux d'abstention") +
  theme_minimal()
```

Il y a aussi une corrélation positive entre le taux de chômage et le taux d'abstention. 





```{r}
# Relation entre le taux d'abstention et le salaire moyen
ggplot(df, aes(x = Salairemoy, y = txabs)) +
  geom_point(color = "purple") +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Salaire moyen vs Taux d'abstention", x = "Salaire moyen", y = "Taux d'abstention") +
  theme_minimal()
```


Il semble que les départements avec un salaire moyen plus bas aient tendance à avoir un taux d'abstention plus fort.


```{r}
# Sélectionner uniquement les colonnes numériques
df_numeric <- df[, sapply(df, is.numeric)]

# Créer la matrice de corrélation uniquement avec les variables numériques
corr_matrix <- cor(df_numeric, use = "complete.obs")

# Transformer la matrice de corrélation en format long (nécessaire pour ggplot2)
melted_corr_matrix <- melt(corr_matrix)

# Créer la heatmap avec ggplot2
ggplot(data = melted_corr_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Corrélation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 10),
        axis.text.y = element_text(size = 10)) +
  coord_fixed() +
  labs(title = "Matrice de corrélation")
```

## données compositionnelles


```{r}
# Sélectionner les variables compositionnelles du jeu de données
compositional_vars <- df[, c("Ouvrier", "Employe", "PI", "Cadres", "Artisant", "Agri")]

# Appliquer la transformation CLR
clr_data <- clr(compositional_vars)

# Convertir le résultat en data frame
clr_df <- as.data.frame(clr_data)

# Afficher les premières lignes des données CLR
head(clr_df)
```

```{r}
# Sélectionner les autres variables quantitatives
other_vars <- df[, c("HLM", "Salairemoy", "TxPauv", "NonDiplome", "txcho", "txabs")]

# Combiner les données CLR transformées avec ces autres variables quantitatives
final_df <- cbind(clr_df, other_vars)

# Afficher les premières lignes du data frame combiné
head(final_df)
```

```{r}
final_df <- scale(final_df,center = TRUE,scale=TRUE)

```



```{r}
# Réaliser une ACP sur toutes les variables (CLR + autres quantitatives)
res.pca <- PCA(final_df, graph = FALSE)

# Résumé des résultats de l'ACP
summary(res.pca)
```


```{r}
# Visualiser la variance expliquée par chaque composante (scree plot)
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

Le scree plot montre que les deux premières composantes principales (Dim 1 et Dim 2) expliquent ensemble 59.8 % de la variance totale (33.8 % pour Dim 1 et 26 % pour Dim 2). Cela signifie que ces deux dimensions capturent l'essentiel de l'information dans les données, ce qui justifie leur utilisation pour une analyse simplifiée.


```{r}
# Extraire les variances expliquées par chaque composante
eig.val <- res.pca$eig

# Calculer la variance cumulée
variance_expliquee <- eig.val[, 2]  # Prendre la deuxième colonne qui est la variance expliquée en pourcentage
variance_cumulee <- cumsum(variance_expliquee)  # Calculer la somme cumulée

# Créer un DataFrame pour visualiser
df_variance <- data.frame(
  Dim = 1:length(variance_expliquee),
  Variance = variance_expliquee,
  CumulativeVariance = variance_cumulee
)

# Visualiser la variance cumulée avec étiquettes sur les points
ggplot(df_variance, aes(x = Dim)) +
  geom_bar(aes(y = Variance), stat = "identity", fill = "steelblue") +
  geom_line(aes(y = CumulativeVariance, group = 1), color = "red", size = 1) +
  geom_point(aes(y = CumulativeVariance), color = "red", size = 2) +
  geom_text(aes(y = CumulativeVariance, label = round(CumulativeVariance, 1)), vjust = -0.5, color = "red") +
  labs(
    title = "Variance expliquée et cumulée par chaque composante",
    x = "Composantes principales",
    y = "Pourcentage de variance expliquée (%)"
  ) +
  scale_y_continuous(sec.axis = sec_axis(~ ., name = "Variance cumulée (%)")) +
  theme_minimal()
```




```{r}
# Visualiser les variables sur le plan factoriel
fviz_pca_var(res.pca, col.var = "contrib", 
             gradient.cols = c("blue", "yellow", "red"),
             repel = TRUE)
```


Le cercle des corrélations illustre les relations entre les variables et les deux premières composantes principales. Les variables PI, Cadres, et Agri contribuent fortement à Dim 1, tandis que Employe, Artisant, et Salairemoy dominent Dim 2. Les flèches proches représentent des corrélations entre les variables, par exemple, Artisant, Ouvrier, et txcho sont fortement corrélés et liés à des métiers manuels et des difficultés socio-économiques.


### Analyse des variables :

#### Variables fortement corrélées à Dim 1 :
Les variables **PI**, **Cadres** contribuent fortement à Dim 1. Cela suggère que cette dimension est associée à des professions plus qualifiées ou bien rémunérées.

#### Variables fortement corrélées à Dim 2 :
Les variables **TxPauv**, **Artisant**, **txcho** et **Ouvrier** sont plus corrélées à Dim 2. Ces variables représentent davantage des difficultés socio-économiques.

#### Corrélation entre variables :
- **Txcho** et **txabs** (taux de chômage et taux d’abstention) sont proches et dans la même direction, ce qui indique une corrélation positive entre ces variables. Plus le taux de chômage est élevé, plus le taux d'abstention pourrait l'être.
- **Salairemoy** et **Cadres** sont également proches, montrant une forte association entre ces deux variables, ce qui est logique car les cadres sont généralement mieux rémunérés.
- **Nondiplome** est dans une direction opposée à **Salairemoy** ce qui suggère que dans les zones à faible revenu, les non diplomé sont plus courant.

#### Contribution des variables :
- Le code de couleur montre la contribution des variables à la variance expliquée par les deux dimensions.
- Les variables comme **PI**, **Cadres**, **Employe**, et **Agri** ont une forte contribution (orange/rouge).
- Les variables comme **TxPauv** et **HLM** contribuent moins à la variance (bleu/violet).

### Résumé :
- **Dim 1** semble capturer des informations relatives à la position socio-économique favorable (professions qualifiées, revenus élevés).
- **Dim 2** est plus lié à des variables socio-économiques représentant des difficultés (chômage, pauvreté, métiers manuels).




```{r}
# Contribution des variables à la première composante (Dim 1)
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
```


Les variables PI, Cadres, et Agri contribuent le plus à la première composante principale (Dim 1), indiquant que cette dimension capture surtout des informations liées aux professions intermédières, aux cadres et à l’agriculture.


```{r}
# Extraire les contributions des variables à Dim 1
contrib_dim1 <- res.pca$var$contrib[,1]

# Créer un dataframe avec les contributions
df_contrib <- data.frame(Variable = names(contrib_dim1), Contribution = contrib_dim1)

# Trier par ordre décroissant et garder les 10 premières contributions
df_contrib <- df_contrib[order(df_contrib$Contribution, decreasing = TRUE),]
df_contrib_top10 <- df_contrib[1:10,]

# Visualisation avec ggplot2
library(ggplot2)
ggplot(df_contrib_top10, aes(x = reorder(Variable, Contribution), y = Contribution)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(Contribution, 1), "%")), 
            vjust = -0.5, size = 3.5) +  # Ajouter les pourcentages sur les barres
  labs(title = "Contribution des variables à la première composante (Dim 1)",
       x = "Variable", 
       y = "Contribution (%)") +
  theme_minimal() +
  coord_flip()  # Inverser les axes pour une meilleure lisibilité
```



```{r}
# Extraire les contributions des variables à la première composante (Dim 1)
contrib_dim1 <- res.pca$var$contrib[, 1]  # Contributions à Dim 1

# Créer un DataFrame pour les contributions
df_contrib <- data.frame(
  Variable = names(contrib_dim1),
  Contribution = contrib_dim1
)

# Trier par ordre décroissant de contribution
df_contrib <- df_contrib %>%
  arrange(desc(Contribution))

# Calculer la contribution cumulée
df_contrib <- df_contrib %>%
  mutate(CumulativeContribution = cumsum(Contribution))

# Visualiser les contributions avec la ligne cumulée
ggplot(df_contrib, aes(x = reorder(Variable, -Contribution))) +
  geom_bar(aes(y = Contribution), stat = "identity", fill = "steelblue") +
  geom_line(aes(y = CumulativeContribution, group = 1), color = "red", size = 1) +
  geom_point(aes(y = CumulativeContribution), color = "red", size = 2) +
  geom_text(aes(y = CumulativeContribution, label = round(CumulativeContribution, 1)), vjust = -0.5, color = "red") +
  labs(
    title = "Contribution cumulée des variables à la première composante (Dim 1)",
    x = "Variables",
    y = "Contribution (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Incliner le texte de l'axe X pour une meilleure lisibilité
```

### Analyse de la contribution cumulée des variables à la première composante (Dim 1)

**Variance cumulée des variables les plus importantes :**
   - **PI**, **Cadres**, **Agri**, **Employe**, et **Salairemoy** totalisent une variance cumulée de **82%** pour la première dimension (Dim 1). 
   - Ces variables jouent un rôle crucial dans la définition de Dim 1. Elles représentent la majeure partie de l'information capturée par cette composante.

**Interprétation :**
   - **PI** (Position Internationale) et **Cadres** dominent cette dimension, ce qui suggère que Dim 1 est fortement influencée par des variables liées à des professions qualifiées, à la position socio-économique élevée, et au capital humain. 
   - **Agri** (Agriculture), **Employe**, et **Salairemoy** (Salaire moyen) viennent compléter cette dimension. Leur contribution importante montre que Dim 1 représente à la fois le secteur agricole, les employés de secteurs plus généraux, et les niveaux de revenus.
   - Les variables **NonDiplome**, **TxPauv** (Taux de pauvreté), **txcho** (Taux de chômage), **Ouvrier**, et **Artisant** ont une contribution cumulée beaucoup plus faible, n'ajoutant que les **18%** restants à Dim 1. Ces variables jouent donc un rôle moins important dans cette dimension, reflétant peut-être une faible corrélation avec les aspects socio-économiques favorisés représentés par Dim 1.

### Conclusion :
Dim 1 capture essentiellement des informations socio-économiques liées aux professions qualifiées et aux revenus. Les variables comme **PI**, **Cadres** y jouent un rôle prédominant, indiquant que cette dimension est principalement associée aux facteurs de réussite sociale et économique.




```{r}
# Contribution des variables à la deuxième composante (Dim 2)
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
```


Les variables Employe, Artisant, Salairemoy, et Ouvrier dominent la contribution à la deuxième composante principale (Dim 2), indiquant que cette dimension est principalement axée sur des profession subordonnée et des métiers manuels, avec une influence notable du chômage (txcho).


```{r}
# Extraire les contributions des variables à Dim 2
contrib_dim2 <- res.pca$var$contrib[,2]

# Créer un dataframe avec les contributions
df_contrib_dim2 <- data.frame(Variable = names(contrib_dim2), Contribution = contrib_dim2)

# Trier par ordre décroissant et garder les 10 premières contributions
df_contrib_dim2 <- df_contrib_dim2[order(df_contrib_dim2$Contribution, decreasing = TRUE),]
df_contrib_dim2_top10 <- df_contrib_dim2[1:10,]

# Visualisation avec ggplot2
library(ggplot2)
ggplot(df_contrib_dim2_top10, aes(x = reorder(Variable, Contribution), y = Contribution)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(Contribution, 1), "%")), 
            vjust = -0.5, size = 3.5) +  # Ajouter les pourcentages sur les barres
  labs(title = "Contribution des variables à la deuxième composante (Dim 2)",
       x = "Variable", 
       y = "Contribution (%)") +
  theme_minimal() +
  coord_flip()  # Inverser les axes pour une meilleure lisibilité
```

```{r}
# Extraire les contributions des variables à la deuxième composante (Dim 2)
contrib_dim2 <- res.pca$var$contrib[, 2]  # Contributions à Dim 2

# Créer un DataFrame pour les contributions
df_contrib_dim2 <- data.frame(
  Variable = names(contrib_dim2),
  Contribution = contrib_dim2
)

# Trier par ordre décroissant de contribution
df_contrib_dim2 <- df_contrib_dim2 %>%
  arrange(desc(Contribution))

# Calculer la contribution cumulée
df_contrib_dim2 <- df_contrib_dim2 %>%
  mutate(CumulativeContribution = cumsum(Contribution))

# Visualiser les contributions avec la ligne cumulée
ggplot(df_contrib_dim2, aes(x = reorder(Variable, -Contribution))) +
  geom_bar(aes(y = Contribution), stat = "identity", fill = "steelblue") +
  geom_line(aes(y = CumulativeContribution, group = 1), color = "red", size = 1) +
  geom_point(aes(y = CumulativeContribution), color = "red", size = 2) +
  geom_text(aes(y = CumulativeContribution, label = round(CumulativeContribution, 1)), vjust = -0.5, color = "red") +
  labs(
    title = "Contribution cumulée des variables à la deuxième composante (Dim 2)",
    x = "Variables",
    y = "Contribution (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Incliner le texte de l'axe X pour une meilleure lisibilité

```

### Analyse de la contribution cumulée des variables à la deuxième composante (Dim 2)

**Variance cumulée des variables les plus importantes :**
   - **Employe**, **Artisant**, **Salairemoy**, et **Ouvrier** totalisent une variance cumulée de **51.9%** pour la deuxième dimension (Dim 2).
   - Ces variables représentent la moitié de l'information capturée par Dim 2 et sont associées à des catégories professionnelles variées ainsi qu'au revenu.

**Interprétation :**
   - **Employe** et **Artisant** contribuent le plus à cette dimension, suggérant que Dim 2 est fortement influencée par des professions intermédiaires et artisanales.
   - **Salairemoy** et **Ouvrier** renforcent cette influence, montrant que Dim 2 capte à la fois des informations sur les revenus moyens et les professions manuelles (ouvriers).
   - Les variables comme **txcho** (Taux de chômage), **NonDiplome**, **TxPauv**, et **txabs** (Taux d'abstention) viennent compléter la variance capturée par Dim 2. Cela montre que cette dimension est également liée à des facteurs de vulnérabilité socio-économique.
 

### Conclusion :
Dim 2 capture principalement des informations liées aux professions intermédiaires, manuelles et aux revenus moyens. Les variables **Employe**, **Artisant**, **Salairemoy**, et **Ouvrier** y jouent un rôle prépondérant, reflétant une dimension centrée sur les travailleurs et le revenu moyen. En complément, cette dimension inclut également des informations sur la précarité sociale (chômage, pauvreté, absence de diplôme).





```{r}
# Contribution des variables à la troisième composante (Dim 2)
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
```

```{r}
# Extraire les contributions des variables à Dim 3
contrib_dim3 <- res.pca$var$contrib[,3]

# Créer un dataframe avec les contributions
df_contrib_dim3 <- data.frame(Variable = names(contrib_dim3), Contribution = contrib_dim3)

# Trier par ordre décroissant et garder les 10 premières contributions
df_contrib_dim3 <- df_contrib_dim3[order(df_contrib_dim3$Contribution, decreasing = TRUE),]
df_contrib_dim3_top10 <- df_contrib_dim3[1:10,]

# Visualisation avec ggplot2
ggplot(df_contrib_dim3_top10, aes(x = reorder(Variable, Contribution), y = Contribution)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(Contribution, 1), "%")), 
            vjust = -0.5, size = 3.5) +  # Ajouter les pourcentages sur les barres
  labs(title = "Contribution des variables à la troisième composante (Dim 3)",
       x = "Variable", 
       y = "Contribution (%)") +
  theme_minimal() +
  coord_flip()  # Inverser les axes pour une meilleure lisibilité

```

```{r}
# Extraire les contributions des variables à la troisième composante (Dim 3)
contrib_dim3 <- res.pca$var$contrib[, 3]  # Contributions à Dim 3

# Créer un DataFrame pour les contributions
df_contrib_dim3 <- data.frame(
  Variable = names(contrib_dim3),
  Contribution = contrib_dim3
)

# Trier par ordre décroissant de contribution
df_contrib_dim3 <- df_contrib_dim3 %>%
  arrange(desc(Contribution))

# Calculer la contribution cumulée
df_contrib_dim3 <- df_contrib_dim3 %>%
  mutate(CumulativeContribution = cumsum(Contribution))

# Visualiser les contributions avec la ligne cumulée
ggplot(df_contrib_dim3, aes(x = reorder(Variable, -Contribution))) +
  geom_bar(aes(y = Contribution), stat = "identity", fill = "steelblue") +
  geom_line(aes(y = CumulativeContribution, group = 1), color = "red", size = 1) +
  geom_point(aes(y = CumulativeContribution), color = "red", size = 2) +
  geom_text(aes(y = CumulativeContribution, label = round(CumulativeContribution, 1)), vjust = -0.5, color = "red") +
  labs(
    title = "Contribution cumulée des variables à la troisième composante (Dim 3)",
    x = "Variables",
    y = "Contribution (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Incliner le texte de l'axe X pour une meilleure lisibilité
```





```{r}
# Filtrer les individus avec cos² > 50%
ind_cos2 <- apply(res.pca$ind$cos2, 1, max) > 0.5

# Filtrer les variables avec cos² > 50%
var_cos2 <- apply(res.pca$var$cos2, 1, max) > 0.5

# Créer un graphique combiné des individus et des variables
fviz_pca_biplot(res.pca,
                select.ind = list(cos2 = 0.5), # Sélectionner les individus avec cos² > 50%
                select.var = list(cos2 = 0.5), # Sélectionner les variables avec cos² > 50%
                repel = TRUE, # Éviter le chevauchement des étiquettes
                title = "Biplot des Individus et des Variables (cos² > 50%)",
                col.ind = "blue", # Couleur des individus
                col.var = "red" # Couleur des variables
                )
```

### Interprétation des groupes d’individus :

- Les individus proches des variables **Cadres**, **Salairemoy**, et **PI** semblent avoir des niveaux de qualification et de revenu plus élevés.

- Les individus situés à l'extrémité gauche, sont plus associés à **Agri** et **NonDiplome**, ce qui pourrait indiquer qu'ils appartiennent à des secteurs moins qualifiés ou agricoles.

- Ceux au centre sont probablement un mélange de plusieurs caractéristiques, car ils sont moins fortement influencés par les variables extrêmes.



###

```{r}
# Créer des catégories basées sur des bornes ajustées pour équilibrer les groupes
final_df$groupe_abstention <- cut(final_df$txabs,
                                  breaks = quantile(final_df$txabs, probs = seq(0, 1, by = 1/3)),  # Tertiles
                                  labels = c("Faible", "Moyen", "Fort"))

# Vérifier la répartition des groupes
table(final_df$groupe_abstention)

# Afficher les premières lignes pour vérifier les résultats
head(final_df)

```


```{r}
# Visualiser avec l'habillage basé sur le taux d'abstention
fviz_pca_ind(res.pca, 
             habillage = final_df$groupe_abstention,  # Colorer par le taux d'abstention
             addEllipses = TRUE,                 # Ajouter des ellipses autour des groupes
             ellipse.level = 0.68,               # Niveau de confiance pour les ellipses
             palette = "Dark2") +                # Palette de couleurs
  theme_minimal()
```

### Analyse générale des groupes d'abstention (suppositions):

- **Groupe à faible abstention** :
  - Représente des départements où la participation électorale est forte, souvent caractérisés par une population plus urbaine, diplômée, et socialement favorisée. Ces zones montrent un intérêt marqué pour la politique.

- **Groupe à abstention moyenne** :
  - Comprend des départements avec une population plus diversifiée socio-économiquement, ni fortement engagée ni totalement désengagée. Ce groupe pourrait inclure des régions urbaines et semi-urbaines avec une participation électorale modérée.

- **Groupe à forte abstention** :
  - Correspond à des départements avec une faible participation électorale, souvent associés à des populations rurales ou moins favorisées socialement et économiquement. L'abstention pourrait être due à une désillusion politique ou un manque d'intérêt.
  

### Conclusions générales :
- Les groupes à **faible abstention** sont plus urbains, favorisés et engagés électoralement.
- Les groupes à **forte abstention** sont plus ruraux ou en difficulté socio-économique, avec un désintérêt pour les élections.
- Le groupe à **abstention moyenne** présente un profil diversifié, sans caractéristiques socio-économiques extrêmes.

Ces observations suggèrent que la participation électorale varie selon les contextes socio-économiques des départements.


Les clusters ne sont pas clairement distincts, ce qui montre que les groupes d'abstention des départements ne sont pas complètement séparés par des caractéristiques socio-économiques bien définies. Il existe un certain chevauchement entre les groupes, en particulier entre les groupes "Moyen" et "Fort", ce qui suggère que les comportements d'abstention des départements peuvent être influencés par plusieurs facteurs complexes.

Ce manque de distinction nette entre les clusters pourrait indiquer que d'autres facteurs non considérés dans cette analyse jouent un rôle important dans la variation des taux d'abstention des départements.



####


```{r}
# Visualiser avec l'habillage basé sur le taux d'abstention sur les dimensions 3 et 4
fviz_pca_ind(res.pca, 
             habillage = final_df$groupe_abstention,  # Colorer par le taux d'abstention
             addEllipses = TRUE,                 # Ajouter des ellipses autour des groupes
             ellipse.level = 0.68,               # Niveau de confiance pour les ellipses
             axes = c(2, 3),                     # Choisir les dimensions 3 et 4
             palette = "Dark2") +                # Palette de couleurs
  theme_minimal()

```



###


## Cluster



```{r}
if (!require(factoextra)) install.packages("factoextra")
if (!require(cluster)) install.packages("cluster")

library(factoextra)
library(cluster)
```



```{r}
# Détermination du nombre optimal de clusters avec la méthode du coude
fviz_nbclust(final_df, kmeans, method = "wss") + 
    geom_vline(xintercept = 4, linetype = 2) +  # Ajuster le xintercept selon le résultat
    labs(title = "Détermination du Nombre Optimal de Clusters",
         x = "Nombre de Clusters",
         y = "Somme des Carrés Intra-Cluster (WSS)") +
    theme_minimal()
```


```{r}
# Calcul de l'indice de silhouette pour différents nombres de clusters
fviz_nbclust(final_df, kmeans, method = "silhouette") +
    labs(title = "Détermination du Nombre Optimal de Clusters avec la Méthode de la Silhouette",
         x = "Nombre de Clusters",
         y = "Largeur Moyenne de la Silhouette") +
    theme_minimal()

```


```{r}
set.seed(123)  # Pour la reproductibilité
kmeans_result <- kmeans(final_df, centers = 2, nstart = 25)

fviz_cluster(kmeans_result, data = final_df)
```



```{r}
set.seed(123)  # Pour la reproductibilité
k2 <- kmeans(final_df, centers = 2, nstart = 25)
k3 <- kmeans(final_df, centers = 3, nstart = 25)
k4 <- kmeans(final_df, centers = 4, nstart = 25)
k5 <- kmeans(final_df, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = final_df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = final_df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = final_df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = final_df) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3,p4, nrow = 2)

```



```{r}
# Ajouter la colonne de cluster à df
final_df$cluster <- factor(kmeans_result$cluster)
```



```{r}

# Liste des variables quantitatives à visualiser (en excluant la colonne 'cluster')
liste_variable_quanti <- c("PI", "Cadres", "Agri", "Employe", "Artisant", "Ouvrier", "TxPauv", "txcho", "txabs")

# Pour chaque variable quantitative, créer un boxplot par rapport à cluster
for (col in liste_variable_quanti) {
  p <- ggplot(final_df, aes(x = cluster, y = .data[[col]], fill = cluster)) +
    geom_boxplot() +
    scale_fill_brewer(palette = "Set1") +  # Utiliser une palette de couleurs
    labs(title = paste("Boxplot de", col, "par cluster"), x = "Cluster", y = col) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Incliner le texte de l'axe X
          plot.title = element_text(hjust = 0.5))  # Centrer le titre

  # Afficher le boxplot
  print(p)
}
```





```{r}
# Pour chaque variable quantitative, créer un boxplot par rapport à cluster
for (col in liste_variable_quanti) {
  p <- ggplot(final_df, aes(x = .data[[col]], y = txabs, col =cluster, fill = cluster)) +
    geom_point() +
    scale_fill_brewer(palette = "Set1") +  # Utiliser une palette de couleurs
    labs(title = paste("Boxplot de", col, "par cluster"), x = col, y = "txabs") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Incliner le texte de l'axe X
          plot.title = element_text(hjust = 0.5))  # Centrer le titre

  # Afficher le boxplot
  print(p)
}
```



```{r}
ggplot(final_df, aes(x = factor(cluster), fill = groupe_abstention)) +
    geom_bar(position = "dodge") +
    scale_fill_brewer(palette = "Set1") +  # Utiliser une palette de couleurs
    labs(title = "Répartition des taux d'abstention par cluster",
         x = "Cluster",
         y = "Absention") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Incliner le texte de l'axe X
```


## regression logistique multi



```{r}
# Installer le package nnet si nécessaire
if (!require(nnet)) install.packages("nnet")
library(nnet)
```


```{r}
# Vérifier la répartition des groupes
table(final_df$groupe_abstention)

```


```{r}
# Appliquer la régression logistique multinomiale
multinom_model <- multinom(groupe_abstention ~ PI + Cadres + Agri + Employe + Artisant + Salairemoy + Ouvrier + txcho, 
                           data = final_df)

# Résumé des résultats du modèle
summary(multinom_model)

```
### Analyse du Modèle de Régression Multinomiale

Une régression multinomiale a été réalisée pour prédire l'appartenance aux groupes d'abstention (Faible, Moyen, Fort) en fonction de variables socio-économiques (**PI**, **Cadres**, **Agri**, **Employe**, **Artisant**, **Salairemoy**, **Ouvrier**, **txcho**).

#### Coefficients du Modèle
- **PI** : Effet positif pour le groupe "Moyen" (+1.29) et négatif pour "Fort" (-9.94), indiquant une relation inverse avec l'abstention élevée.
- **Cadres** : Négatif pour "Moyen" (-0.73) et positif pour "Fort" (+2.21), favorisant l'appartenance au groupe "Fort".
- **Employe** : Positif pour les groupes "Moyen" (+1.90) et "Fort" (+16.31), montrant une forte association avec l'emploi salarié.

#### Conclusion
**Employe** et **Cadres** sont des contributeurs clés pour les groupes "Moyen" et "Fort". À l'inverse, **Artisant** et **Ouvrier** ont un effet négatif sur l'appartenance au groupe "Fort", indiquant une moindre présence dans ce groupe.



```{r}
# Calculer les z-scores et les p-values
z_scores <- summary(multinom_model)$coefficients / summary(multinom_model)$standard.errors
p_values <- 2 * (1 - pnorm(abs(z_scores)))

# Afficher les p-values pour chaque coefficient
p_values

```
### Analyse des P-valeurs du Modèle Multinomiale

Les P-valeurs associées aux coefficients de la régression multinomiale montrent la significativité des variables pour prédire l'appartenance aux groupes **Moyen** et **Fort** d'abstention, par rapport au groupe de référence (Faible).

#### Interprétation des P-valeurs :

- **Groupe "Moyen"** :
  - **PI** (0.84), **Cadres** (0.80), et **Employe** (0.67) ne sont pas statistiquement significatifs pour prédire l'appartenance au groupe "Moyen".
  - **Ouvrier** (0.79) et **Salairemoy** (0.68) sont également non significatifs.
  - **txcho** (0.03) est significatif, ce qui indique que le taux de chômage est un facteur influençant l'appartenance à ce groupe.

- **Groupe "Fort"** :
  - **Employe** (0.001) et **Artisant** (0.009) sont très significatifs pour le groupe "Fort", montrant une forte relation entre ces variables et une forte abstention.
  - **Agri** (0.01) est également significatif, tandis que **Ouvrier** (0.49) et **Salairemoy** (0.45) ne sont pas significatifs.
  - **txcho** (0.04) est significatif, soulignant le rôle du taux de chômage dans ce groupe.

#### Conclusion :
- Pour le groupe "Fort", **Employe**, **Artisant**, et **Agri** sont les facteurs les plus significatifs.
- Pour le groupe "Moyen", seul **txcho** apparaît comme un facteur statistiquement significatif. Les autres variables sont peu pertinentes pour ce groupe.



```{r}
# Faire des prédictions
predictions <- predict(multinom_model, newdata = final_df)

# Créer une matrice de confusion pour voir les prédictions correctes
confusion_matrix <- table(Predicted = predictions, Actual = final_df$groupe_abstention)
print(confusion_matrix)

# Calculer l'accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
```


### Interprétation de l'Accuracy

L'accuracy du modèle est de **0.6**, ce qui signifie que **60 %** des prédictions faites par le modèle sont correctes, c'est-à-dire que le modèle prédit correctement l'appartenance à l'un des trois groupes d'abstention (Faible, Moyen, Fort) dans 60 % des cas.

#### Interprétation :
- Un taux d'accuracy de 0.6 est relativement moyen. Cela suggère que le modèle capture certaines des relations entre les variables socio-économiques et l'abstention, mais qu'il reste des incertitudes et des erreurs de classification.




```{r}
# Charger les bibliothèques nécessaires
library(ggplot2)
library(reshape2)

# Créer une matrice de confusion sous forme de tableau
conf_mat <- table(Predicted = predictions, Actual = final_df$groupe_abstention)

# Transformer la matrice en format "long" pour ggplot2
conf_mat_melt <- melt(conf_mat)

# Visualiser la matrice de confusion sous forme de heatmap
ggplot(conf_mat_melt, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = value), color = "white") +
  scale_fill_gradient(low = "white", high = "lightblue") +
  geom_text(aes(label = value), vjust = 1) +
  labs(title = "Matrice de confusion", x = "Classe réelle", y = "Classe prédite") +
  theme_minimal()

```

```{r}
# Charger les bibliothèques nécessaires
library(pROC)

# Multinomial model output
probs <- predict(multinom_model, newdata = final_df, type = "prob")

# Créer des courbes ROC pour chaque classe
roc_faible <- roc(final_df$groupe_abstention == "Faible", probs[, "Faible"])
roc_moyen <- roc(final_df$groupe_abstention == "Moyen", probs[, "Moyen"])
roc_fort <- roc(final_df$groupe_abstention == "Fort", probs[, "Fort"])

# Tracer les courbes ROC
plot(roc_faible, col = "blue", main = "Courbes ROC par classe")
plot(roc_moyen, col = "red", add = TRUE)
plot(roc_fort, col = "green", add = TRUE)

legend("bottomright", legend = c("Faible", "Moyen", "Fort"),
       col = c("blue", "red", "green"), lwd = 2)

```




